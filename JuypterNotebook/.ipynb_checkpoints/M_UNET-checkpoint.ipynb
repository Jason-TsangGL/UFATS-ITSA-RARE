{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "72J0nla-XBco"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/keras-team/keras-tuner.git@1.0.1\n",
      "  Cloning https://github.com/keras-team/keras-tuner.git (to revision 1.0.1) to c:\\users\\jglts\\appdata\\local\\temp\\pip-req-build-tysv_6t3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/keras-team/keras-tuner.git 'C:\\Users\\jglts\\AppData\\Local\\Temp\\pip-req-build-tysv_6t3'\n",
      "  WARNING: Did not find branch or tag '1.0.1', assuming revision or ref.\n",
      "  Running command git checkout -q 1.0.1\n",
      "  error: pathspec '1.0.1' did not match any file(s) known to git\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  git checkout -q 1.0.1 did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  See above for output.\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "git checkout -q 1.0.1 did not run successfully.\n",
      "exit code: 1\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib Simpleitk pynrrd git+https://github.com/keras-team/keras-tuner.git@1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CLRSPpRJTO8T"
   },
   "outputs": [],
   "source": [
    "#inhomogeneity correction\n",
    "def correct_roi(image):\n",
    "    inputImage=sitk.GetImageFromArray(image)\n",
    "    inputImage = sitk.Cast(inputImage, sitk.sitkFloat32 )\n",
    "    corrector = sitk.N4BiasFieldCorrectionImageFilter()\n",
    "    output = corrector.Execute( inputImage)\n",
    "    image_c= sitk.GetArrayFromImage(output)\n",
    "    image_c=cv2.normalize(src=image_c, dst=None, alpha=0.0, beta=255.0, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    return image_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQggpihrTsXX"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(\"./runtime-annotations.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"./runtime-annotations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQQKLD2KTO8U"
   },
   "outputs": [],
   "source": [
    "#background noise removal\n",
    "imageI=inputs[:, :, :, 0] #Inputs Variable \n",
    "ArrayI = np.zeros((1755, 256, 256, 1)) \n",
    "for x in range (1755): \n",
    "    for i in range (9):\n",
    "        ArrayI[x,:,:,0]+=mask[x,:,:,i] #Merged MSK Mask\n",
    "ArrayII=ArrayI[:, :, :, 0] # Get rid of [:,:,:,1]\n",
    "INVArrayI=1-ArrayII #Invered Mask\n",
    "INVArrayII=INVArrayI*imageI #Mask multipled with array\n",
    "INVArrayIII=np.where(INVArrayII > 80, 1 , 0) #Get rid of magnetic background noise\n",
    "ArrayIII = INVArrayIII+ArrayII #Add both the merged msk and inv msk together\n",
    "FINALArray=ArrayIII*inputs1 #Multiply new mask with original image\n",
    "for i in range (2):\n",
    "    plt.imshow(FINALArray[i],cmap=plt.cm.bone,vmin=0,vmax=255)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eG85v8FhHYqV"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import os as os\n",
    "import nrrd as reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GrSuSYEPTO8S"
   },
   "outputs": [],
   "source": [
    "def join(one, two):\n",
    "    return os.path.join(one, two)\n",
    "def show(img, *masks):\n",
    "    width = img.shape[0]\n",
    "    height = img.shape[1]\n",
    "    plt.imshow(img.reshape(width, height), cmap=\"gray\")\n",
    "    for mask in masks:\n",
    "        plt.imshow(mask.reshape(width, height), alpha=0.4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yy2MaZEdHYqd"
   },
   "outputs": [],
   "source": [
    "def check_path(path):\n",
    "    count=0\n",
    "    for files in sorted(os.listdir(path)):\n",
    "        image_path = os.path.join(path,files)\n",
    "        count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mQGyLGn0HYqk",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (patient count* 15) check_path function will return total patient count \n",
    "folder_path = join(os.getcwd(), \"runtime-annotations\")\n",
    "\n",
    "length = check_path(folder_path)\n",
    "dicoms = np.zeros((length * 15, 256, 256, 1))\n",
    "masks = np.zeros((length * 15, 256, 256, 1))\n",
    "# masks = np.zeros((length * 15, 256, 256, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RWFniWqdHYqz"
   },
   "outputs": [],
   "source": [
    "def dcm_to_np(path):\n",
    "    global dic_count\n",
    "    try:\n",
    "        slice_filenames = sitk.ImageSeriesReader_GetGDCMSeriesFileNames(path)\n",
    "        image = sitk.ReadImage(slice_filenames)\n",
    "        for x in range(15):\n",
    "            current_array = sitk.GetArrayFromImage(image[:, :, x])\n",
    "            dicoms[dic_count] = current_array[:, :256, np.newaxis]\n",
    "            dic_count += 1\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dNTMbc46HYqt"
   },
   "outputs": [],
   "source": [
    "def nrrd_to_np(meta_object):\n",
    "    global ann_count\n",
    "    try:\n",
    "        data = sitk.GetArrayFromImage(meta_object)\n",
    "        for p in range(15):\n",
    "            masks[ann_count] = np.expand_dims(np.where(data[p, :, :256] == 2, 1, 0), axis=2)\n",
    "            ann_count+=1\n",
    "        print(ann_count)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "# for y, a in enumerate(current_seg):\n",
    "#     for x, b in enumerate(a):\n",
    "#         if b == 1:\n",
    "#             black[y][x][0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bTzZ0175HYrD",
    "outputId": "91998caf-5d5e-424d-a0ca-3845d503e2f3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dic_count = 0\n",
    "ann_count = 0\n",
    "\n",
    "try:\n",
    "    for patient in sorted(os.listdir(folder_path)):\n",
    "        patient_path = join(folder_path, patient)\n",
    "        nrrd_folder = join(patient_path, \"NRRD\")\n",
    "        dcm_to_np(patient_path)\n",
    "        for nrrd in os.listdir(nrrd_folder):\n",
    "            if(\".nrrd\" in nrrd):\n",
    "                segmentation = sitk.ReadImage(join(nrrd_folder, nrrd))\n",
    "                nrrd_to_np(segmentation)\n",
    "                break\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "N1uxjVR0HYrJ",
    "outputId": "67de0995-cdda-4ed7-ebae-53a55d550344",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "number = 150\n",
    "show(dicoms[number], masks[number, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OudojsDbTO8W"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return 1 - (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "def iou(y_pred, y_true):\n",
    "    I = tf.reduce_sum(y_pred * y_true, axis=(1, 2))\n",
    "    U = tf.reduce_sum(y_pred + y_true, axis=(1, 2)) - I\n",
    "    return tf.reduce_mean(I / U)\n",
    "\n",
    "def build_model(hp):\n",
    "#     starting_filters = hp.Int('starting_filters', min_value=16, max_value=48, step=8)\n",
    "#     kernel_shape = hp.Choice('kernel_shape', values=[3, 5])\n",
    "#     dropout = hp.Float('dropout', min_value=0.1, max_value=0.5, step=0.1)\n",
    "    \n",
    "    starting_filters: 48\n",
    "    kernel_shape: 3\n",
    "    dropout: 0.1\n",
    "    learning_rate: 1e-05\n",
    "\n",
    "    input_layer = Input((256, 256, 1))\n",
    "\n",
    "    conv1 = Conv2D(starting_filters * 1, (kernel_shape, kernel_shape), activation=\"relu\", padding=\"same\")(input_layer)\n",
    "    conv1 = Conv2D(starting_filters * 1, (kernel_shape, kernel_shape), activation=\"relu\", padding=\"same\")(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    pool1 = Dropout(dropout)(pool1)\n",
    "\n",
    "    conv2 = Conv2D(starting_filters * 2, (kernel_shape, kernel_shape), activation=\"relu\", padding=\"same\")(pool1)\n",
    "    conv2 = Conv2D(starting_filters * 2, (kernel_shape, kernel_shape), activation=\"relu\", padding=\"same\")(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    pool2 = Dropout(dropout)(pool2)\n",
    "\n",
    "    conv3 = Conv2D(starting_filters * 4, (kernel_shape, kernel_shape), activation=\"relu\", padding=\"same\")(pool2)\n",
    "    conv3 = Conv2D(starting_filters * 4, (kernel_shape, kernel_shape), activation=\"relu\", padding=\"same\")(conv3)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "    pool3 = Dropout(dropout)(pool3)\n",
    "\n",
    "    conv4 = Conv2D(starting_filters * 8, (kernel_shape, kernel_shape), activation=\"relu\", padding=\"same\")(pool3)\n",
    "    conv4 = Conv2D(starting_filters * 8, (kernel_shape, kernel_shape), activation=\"relu\", padding=\"same\")(conv4)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = Dropout(dropout)(pool4)\n",
    "\n",
    "    # Middle\n",
    "    convm = Conv2D(starting_filters * 16, (kernel_shape, kernel_shape), activation=\"relu\", padding=\"same\")(pool4)\n",
    "    convm = Conv2D(starting_filters * 16, (kernel_shape, kernel_shape), activation=\"relu\", padding=\"same\")(convm)\n",
    "\n",
    "    deconv4 = Conv2DTranspose(starting_filters * 8, (kernel_shape, kernel_shape), strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    uconv4 = Dropout(dropout)(uconv4)\n",
    "    uconv4 = Conv2D(starting_filters * 8, (kernel_shape, kernel_shape), activation=\"relu\", padding=\"same\")(uconv4)\n",
    "    uconv4 = Conv2D(starting_filters * 8, (kernel_shape, kernel_shape), activation=\"relu\", padding=\"same\")(uconv4)\n",
    "\n",
    "    deconv3 = Conv2DTranspose(starting_filters * 4, (kernel_shape, kernel_shape), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "    uconv3 = concatenate([deconv3, conv3])\n",
    "    uconv3 = Dropout(dropout)(uconv3)\n",
    "    uconv3 = Conv2D(starting_filters * 4, (kernel_shape, kernel_shape), activation=\"relu\", padding=\"same\")(uconv3)\n",
    "    uconv3 = Conv2D(starting_filters * 4, (kernel_shape, kernel_shape), activation=\"relu\", padding=\"same\")(uconv3)\n",
    "\n",
    "    deconv2 = Conv2DTranspose(starting_filters * 2, (kernel_shape, kernel_shape), strides=(2, 2), padding=\"same\")(uconv3)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "    uconv2 = Dropout(dropout)(uconv2)\n",
    "    uconv2 = Conv2D(starting_filters * 2, (kernel_shape, kernel_shape), activation=\"relu\", padding=\"same\")(uconv2)\n",
    "    uconv2 = Conv2D(starting_filters * 2, (kernel_shape, kernel_shape), activation=\"relu\", padding=\"same\")(uconv2)\n",
    "\n",
    "    deconv1 = Conv2DTranspose(starting_filters * 1, (kernel_shape, kernel_shape), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    uconv1 = Dropout(dropout)(uconv1)\n",
    "    uconv1 = Conv2D(starting_filters * 1, (kernel_shape, kernel_shape), activation=\"relu\", padding=\"same\")(uconv1)\n",
    "    uconv1 = Conv2D(starting_filters * 1, (kernel_shape, kernel_shape), activation=\"relu\", padding=\"same\")(uconv1)\n",
    "\n",
    "    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "#     opt = Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4, 1e-5]))\n",
    "    opt = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=opt, loss=dice_coef_loss, metrics=[iou])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_iou', patience=15, mode='max', min_delta=0.001)\n",
    "tensorboard = TensorBoard(log_dir='logs')\n",
    "tuner.search(dicoms, masks, epochs=250, batch_size=16, validation_split=0.1, callbacks=[early_stopping, tensorboard], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ZiYmosXTO8c"
   },
   "outputs": [],
   "source": [
    "from kerastuner.tuners.bayesian import BayesianOptimization\n",
    "from kerastuner import Objective\n",
    "\n",
    "tuner = BayesianOptimization(\n",
    "    build_model,\n",
    "    objective=Objective('val_iou', direction='max'),\n",
    "    max_trials=80,\n",
    "    executions_per_trial=1,\n",
    "    directory=\"./\",\n",
    "    project_name='training_runs',\n",
    "    overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ptHG57lDTO8d",
    "outputId": "ff9ff90b-e8c8-468a-edbb-2ea9b3028e78",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_iou', patience=15, mode='max', min_delta=0.001)\n",
    "tensorboard = TensorBoard(log_dir='logs')\n",
    "tuner.search(dicoms, masks, epochs=250, batch_size=16, validation_split=0.1, callbacks=[early_stopping, tensorboard], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tuner.get_best_models(2)[0]\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "for number in range(100):\n",
    "#     number = random.randint(0, len(X_test))\n",
    "    prediction = model.predict(dicoms[number].reshape(1, 256, 256, 1)).reshape(256, 256)\n",
    "    show(dicoms[number])\n",
    "    show(dicoms[number], prediction)\n",
    "    show(dicoms[number], masks[number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KuJksH29HYrV"
   },
   "outputs": [],
   "source": [
    "plt.title(\"Metrics\")\n",
    "plt.plot(results.history[\"loss\"], label=\"loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3jOf7tH_HYra"
   },
   "outputs": [],
   "source": [
    "result = model.predict(inputs[100].reshape(1, 256, 512, 1))\n",
    "plt.imshow(inputs[100].reshape(256, 512), cmap=plt.cm.bone)\n",
    "plt.show()\n",
    "plt.imshow(result[0][:, :, 3])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "v2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
